{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocessing\n",
    "\"\"\"\n",
    "# let's impute the missing default_profile_image data for our training and test sets\n",
    "# we need to scale before using KNN imputation \n",
    "# we need to perform scaling and imputation on the training set, then pull the parameters for the test\n",
    "# we'll use RobustScaler since we have a lot of outliers -- our means are rather useless\n",
    "\n",
    "# fit the scaler to our resampled X_train and transform X_train and X_test\n",
    "# scaler = RobustScaler().fit(X_train_res)\n",
    "# X_train_res_sca = pd.DataFrame(scaler.transform(X_train_res), columns=X_train.columns)\n",
    "# X_test_sca = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)\n",
    "\n",
    "# # This will need to be undone and placed in a pipeline when we do validation\n",
    "\n",
    "# # fit the imputer to our scaled X_train, use it to impute train and test and cast to DataFrames\n",
    "# imputer = KNNImputer(n_neighbors=3).fit(X_train_res_sca)\n",
    "# X_train_final = pd.DataFrame(imputer.transform(X_train_res_sca), columns=X.columns)\n",
    "# X_test_final = pd.DataFrame(imputer.transform(X_test_sca), columns=X.columns)\n",
    "\n",
    "# # round the imputed to 0 and 1, +1 to return to 0-1 scale\n",
    "# X_train_final['default_profile'] = X_train_final['default_profile'].round() + 1\n",
    "# X_test_final['default_profile'] = X_test_final['default_profile'].round() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit with C=1, 10k iterations\n",
    "logit = LogisticRegression(C=1, max_iter=10000)\n",
    "logit.fit(X_train_final, y_train_res)\n",
    "log_pred = logit.predict(X_test_final)\n",
    "log_F1 = f1_score(y_test, log_pred)\n",
    "log_recall = recall_score(y_test, log_pred)\n",
    "print(\"The score for logistic regression is\")\n",
    "print(\"Training acc: {:6.2f}%\".format(100*logit.score(X_train_final, y_train_res)))\n",
    "print(\"Test acc: {:6.2f}%\".format(100*logit.score(X_test_final, y_test)))\n",
    "print(\"Test recall: {:6.2f}%\".format(100*log_recall))\n",
    "print(\"Test F1: {:6.2f}%\".format(100*log_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K=5 KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ros, y_train_ros)\n",
    "knn_pred = knn.predict(X_val)\n",
    "knn_F1 = f1_score(y_val, knn_pred)\n",
    "knn_recall = recall_score(y_val, knn_pred)\n",
    "print(\"The score for kNN is\")\n",
    "print(\"Training acc: {:6.2f}%\".format(100*knn.score(X_train_ros, y_train_ros)))\n",
    "print(\"Test set acc: {:6.2f}%\".format(100*knn.score(X_val, y_val)))\n",
    "print(\"Test recall: {:6.2f}%\".format(100*knn_recall))\n",
    "print(\"Test F1: {:6.2f}%\".format(100*knn_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaiveBayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_final, y_train_res)\n",
    "nb_pred = nb.predict(X_test_final)\n",
    "nb_F1 = f1_score(y_test, nb_pred)\n",
    "nb_recall = recall_score(y_test, nb_pred)\n",
    "print(\"The score for Naive Bayes is\")\n",
    "print(\"Training acc: {:6.2f}%\".format(100*nb.score(X_train_final, y_train_res)))\n",
    "print(\"Test set acc: {:6.2f}%\".format(100*nb.score(X_test_final, y_test)))\n",
    "print(\"Test recall: {:6.2f}%\".format(100*nb_recall))\n",
    "print(\"Test F1: {:6.2f}%\".format(100*nb_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_final, y_train_res)\n",
    "tree_pred = tree.predict(X_test_final)\n",
    "tree_F1 = f1_score(y_test, tree_pred)\n",
    "tree_recall = recall_score(y_test, tree_pred)\n",
    "print(\"The score for Decision Tree is\")\n",
    "print(\"Training acc: {:6.2f}%\".format(100*tree.score(X_train_final, y_train_res)))\n",
    "print(\"Test set acc: {:6.2f}%\".format(100*tree.score(X_test_final, y_test)))\n",
    "print(\"Test recall: {:6.2f}%\".format(100*tree_recall))\n",
    "print(\"Test F1: {:6.2f}%\".format(100*tree_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train_final, y_train_res)\n",
    "forest_pred = forest.predict(X_test_final)\n",
    "forest_F1 = f1_score(y_test, forest_pred)\n",
    "forest_recall = recall_score(y_test,forest_pred)\n",
    "print(\"The score for Random Forest is\")\n",
    "print(\"Training acc: {:6.2f}%\".format(100*forest.score(X_train_final, y_train_res)))\n",
    "print(\"Test set acc: {:6.2f}%\".format(100*forest.score(X_test_final, y_test)))\n",
    "print(\"Test recall: {:6.2f}%\".format(100*forest_recall))\n",
    "print(\"Test F1: {:6.2f}%\".format(100*forest_F1))"
   ]
  }
 ]
}